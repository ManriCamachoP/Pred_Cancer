---
title: "1_regresion_logistica"
format: html
editor: visual
---

# Configuración general

```{r}
# Configuración base de R: 
rm(list = ls(all.names = TRUE)) 

# Semillas:
RNGkind(sample.kind = "Rounding")

# Semilla para los análisis aleatorios: 
set.seed(1234)
```

## Librerías

```{r}
pacman::p_load(
  # Lectura y manipulación de datos: 
  tidyverse, magrittr, rio, here, caret, glmnet, performance, pROC,
  
  # Arboles:
  rpart, rattle, randomForest, ipred,
  
  # Tablas de frecuencia, gráficos y demás:
  ggthemes, scales
)
```


## Datos

```{r}
# Cargar la base de datos:
base = read_csv("C:/Users/Ivan RC/Desktop/OneDrive - Universidad Latina/I-2024/2. Análisis Multivariado/Proyectos/Pred_Cancer/data/processed/data.csv")

# Vizualizar la base:
base1 = base %>% 
  mutate_at(
    .vars = vars(State, Sex, Marital, Race, Education,
                 GeneralHealth, Exercise, TypeSmoker,
                 WalkingDiff, MentalDis, EverMammo,
                 TimeMammo, DiffCancer, BreastCancer), 
    .funs = as.factor
    ) %>% 
  rename(ID = 1)

# Cambiar la categoría de referencia en la respuesta:
base1$BreastCancer = relevel(x = base1$BreastCancer, ref = "No Breast Cancer")
contrasts(base1$BreastCancer)

# Ver las categorías de referencia del sexo:
contrasts(base1$Sex)
```

------------------------------------------------------------------------

# Modelo logístico

Fuente: https://stats.oarc.ucla.edu/r/dae/logit-regression/

## Análisis descriptivo

```{r}
base1 %>% 
  group_by(BreastCancer, Sex) %>% 
  summarise(
    casos_totales = n(),
    edad_media_persona = mean(Age, na.rm = T),
    edad_diagnostico = mean(AgeCancer, na.rm = T) 
    ) %>% 
  mutate(casos_totales = as.numeric(casos_totales))
```

## Selección de variables: Sin NA

Para prevenir posibles errores en la convergencia del modelo logístico. Se decidió omitir aquellas variables que poseían valores faltantes (NA).

```{r}
base2 = base1 %>% select(where(~all(!is.na(.))))

# Verificar si cada variable tiene algún NA:
sapply(base2, function(x) sum(is.na(x)))

# Omitir el ID:
base2 = base2 %>% select(-ID)
```

## Correlaciones

Verificar la correrlación entre las variables numéricas.

```{r}
base2 %>% select_if(is.numeric) %>% correlation::correlation()
```

## Partición de la muestra

Se trabaja con una muestra de 80% para entrenamiento y 20% para la prueba o testeo.

```{r}
# Partición de los datos
train = createDataPartition(
  # Variable respuesta:
  y = base2$BreastCancer,
  # Proporción de los datos:
  p = 0.8,
  # No devolver la lista de los ID seleccionados:
  list = F
)

# Base de entrenamiento: 
training = base2[train,]

# Base de prueba (testeo):
testing = base2[-train,] 
```

## Modelo

### Manual

Las variables de Age y TimeSlept generaron que no se puediera estimar el modelo en conjunto con las demás variables. Por ende, para este caso se omitieron.

```{r}
base2 %>% names()
```

```{r}
mod1 = glm(
  formula = BreastCancer ~ State + Sex + Marital + Race + Weight + Height + Education + GeneralHealth + MentalHealth + Exercise + TypeSmoker + WalkingDiff + MentalDis + DiffCancer + AgeCancer, 
  family = binomial(link = "log"), 
  data = training 
  )
```

Además, se analizaron distintos apartados del modelo estimado:

```{r}
# Multicolinealidad:
mod1 %>% performance::multicollinearity()

# Autocorrelación:
mod1 %>% performance::check_autocorrelation()

# Valores extremos
mod1 %>% performance::check_outliers()

# Residuos:
mod1 %>% performance::check_residuals()
```

## Modelo de entrenamiento caret

Para este caso se hace uso de las funciones de la librería caret para estimar el modelo logístico el cual se realiza implementando de una vez la validación cruzada con 10 pliegos.

```{r}
# Especificar el control por validación cruzada con diez pliegos:
train_control = trainControl(method = "cv", number = 10)

# Ajustar el modelo logístico con la base de entrenamiento:
cv_model = train(
  BreastCancer ~ State + Sex + Marital + Race + Weight + Height + Education + GeneralHealth + MentalHealth + Exercise + TypeSmoker + WalkingDiff + MentalDis + DiffCancer + AgeCancer, 
  data = training, 
  method = "glm", 
  family = binomial, 
  trControl = train_control
  )

# Verificar el accuracy del modelo:
print(cv_model)

# Observar el accuracy para cada pliego estimado:
cv_model$resample 
```

### Métricas de validación

```{r}
# Estimación de las predicciones en formato de probabilidad: 
pred_prob = predict(cv_model, newdata = testing, type = "prob") %>% round(4)
pred_prob %>% mutate(original = testing$BreastCancer)
```

```{r}
# Probabilidades estimadas para las personas con cancer de mama:
pred_prob_cancer = pred_prob[, "Breast Cancer"]

# Curva ROC:
roc_curve = roc(testing$BreastCancer, pred_prob_cancer)

# Gráficar la curva ROC:
plot(roc_curve)

# Área debajo de la curva:  
auc_value = auc(roc_curve) ; auc_value
```


---

# Arboles 

```{r}
library(rpart) ; library(rattle)
```


```{r}
arbol1 = rpart(formula = BreastCancer ~., 
               method = "class", 
               control = rpart.control(minsplit = 20, cp = 0.01),
               data = training)

arbol1 %>% summary()

fancyRpartPlot(arbol1)
```


---

# Bagging

```{r}
bag1 = bagging(formula = BreastCancer ~ ., 
  data = training, 
  nbagg = 50,    
  coob = TRUE, 
  mfinal = 19,
  control = rpart.control(minsplit = 2, cp = 0,  min_depth = 2))
```


dura aprox 18-19 min

```{r}
bag2 <- train(
  BreastCancer ~ .,
  data = training,
  method = "treebag",
  trControl = trainControl(method = "cv", number = 10),
  nbagg = 50,  
  control = rpart.control(minsplit = 2, cp = 0)
)

# Predicciones
predictions  = predict(bag2, newdata = testing)

roc_curve <- roc(testing$BreastCancer, as.numeric(predictions))
plot(roc_curve)
auc(roc_curve)

varImp(bag2)

bag2$results
bag2$resample
```


